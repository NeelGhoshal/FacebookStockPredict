{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FacebookStockPredict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE_W-x4zHc43",
        "outputId": "19f6d106-3189-48be-888b-7bf12b542031"
      },
      "source": [
        "pip install tensorflow pandas numpy matplotlib yahoo_fin sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Collecting yahoo_fin\n",
            "  Downloading yahoo_fin-0.8.9.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (57.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.5.0)\n",
            "Collecting pyquery\n",
            "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting pyppeteer>=0.0.14\n",
            "  Downloading pyppeteer-0.2.5-py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (0.0.1)\n",
            "Collecting w3lib\n",
            "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting fake-useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "Collecting importlib-metadata\n",
            "  Downloading importlib_metadata-2.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting websockets<9.0,>=8.1\n",
            "  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
            "Collecting pyee<9.0.0,>=8.1.0\n",
            "  Downloading pyee-8.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting tqdm<5.0.0,>=4.42.1\n",
            "  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html->yahoo_fin) (4.6.3)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html->yahoo_fin) (4.2.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Building wheels for collected packages: fake-useragent, parse, sgmllib3k\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13503 sha256=449628d6250ed9c2b48dfdda168014234e5cdf4baeb697bed693ca80c9037c6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=0d4822b5b1670251f39f35b2acdda4ac7a5a60cfafa4ac600058a3ec0af5afe7\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/aa/cc/f2228050ccb40f22144b073f15a2c84f11204f29fc0dce028e\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=0a43b68de6d90a6afade9cabee2d05f1d8702b8b06c1bb5ba15a47f9f0b90430\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built fake-useragent parse sgmllib3k\n",
            "Installing collected packages: urllib3, websockets, tqdm, pyee, importlib-metadata, cssselect, w3lib, sgmllib3k, pyquery, pyppeteer, parse, fake-useragent, requests-html, feedparser, yahoo-fin\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.1\n",
            "    Uninstalling importlib-metadata-4.6.1:\n",
            "      Successfully uninstalled importlib-metadata-4.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed cssselect-1.1.0 fake-useragent-0.1.11 feedparser-6.0.8 importlib-metadata-2.1.1 parse-1.19.0 pyee-8.1.0 pyppeteer-0.2.5 pyquery-1.4.3 requests-html-0.10.0 sgmllib3k-1.0.0 tqdm-4.61.2 urllib3-1.25.11 w3lib-1.22.0 websockets-8.1 yahoo-fin-0.8.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QulsfdaHfAB"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgCsqDzEHkwT",
        "outputId": "ad68d0cb-ecc1-4c8e-d963-f2d848645e7f"
      },
      "source": [
        "pip install requests_html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests_html in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.7/dist-packages (from requests_html) (1.4.3)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from requests_html) (0.1.11)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from requests_html) (0.2.5)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.7/dist-packages (from requests_html) (1.22.0)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.7/dist-packages (from requests_html) (1.19.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests_html) (0.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from requests_html) (2.23.0)\n",
            "Requirement already satisfied: websockets<9.0,>=8.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (8.1)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.25.11)\n",
            "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (8.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.61.2)\n",
            "Requirement already satisfied: importlib-metadata<3.0.0,>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (2.1.1)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<3.0.0,>=2.1.1->pyppeteer>=0.0.14->requests_html) (3.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests_html) (4.6.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests_html) (4.2.6)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests_html) (1.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (2.10)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from w3lib->requests_html) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3E2RVmGHnCS"
      },
      "source": [
        "# set seed, so we can get the same results after rerunning several times\n",
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK4AYznEHnaj"
      },
      "source": [
        "def shuffle_in_unison(a, b):\n",
        "    \n",
        "    state = np.random.get_state()\n",
        "    np.random.shuffle(a)\n",
        "    np.random.set_state(state)\n",
        "    np.random.shuffle(b)\n",
        "\n",
        "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
        "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "    \n",
        "    \n",
        "    if isinstance(ticker, str):\n",
        "       \n",
        "        df = si.get_data(ticker)\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "     \n",
        "        df = ticker\n",
        "    else:\n",
        "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
        "    \n",
        "    result = {}\n",
        "    \n",
        "    result['df'] = df.copy()\n",
        "\n",
        "    for col in feature_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "\n",
        "    if \"date\" not in df.columns:\n",
        "        df[\"date\"] = df.index\n",
        "    if scale:\n",
        "        column_scaler = {}\n",
        "      \n",
        "        for column in feature_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "            column_scaler[column] = scaler\n",
        "        \n",
        "        result[\"column_scaler\"] = column_scaler\n",
        "    \n",
        "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
        "\n",
        "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
        "    \n",
        "    df.dropna(inplace=True)\n",
        "    sequence_data = []\n",
        "    sequences = deque(maxlen=n_steps)\n",
        "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
        "        sequences.append(entry)\n",
        "        if len(sequences) == n_steps:\n",
        "            sequence_data.append([np.array(sequences), target])\n",
        "   \n",
        "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
        "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
        "   \n",
        "    result['last_sequence'] = last_sequence\n",
        "    \n",
        "    X, y = [], []\n",
        "    for seq, target in sequence_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "    \n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    if split_by_date:\n",
        "       \n",
        "        train_samples = int((1 - test_size) * len(X))\n",
        "        result[\"X_train\"] = X[:train_samples]\n",
        "        result[\"y_train\"] = y[:train_samples]\n",
        "        result[\"X_test\"]  = X[train_samples:]\n",
        "        result[\"y_test\"]  = y[train_samples:]\n",
        "        if shuffle:\n",
        "           \n",
        "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
        "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
        "    else:    \n",
        "        \n",
        "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
        "                                                                                test_size=test_size, shuffle=shuffle)\n",
        "    \n",
        "    dates = result[\"X_test\"][:, -1, -1]\n",
        "   \n",
        "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
        "    \n",
        "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
        "  \n",
        "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
        "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWl2v49rHt8q"
      },
      "source": [
        "\n",
        "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
        "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            # first layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
        "        elif i == n_layers - 1:\n",
        "            # last layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "            # hidden layers\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True))\n",
        "        # add dropout after each layer\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-IYpAl_Hve-"
      },
      "source": [
        "import os\n",
        "import time\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "\n",
        "N_STEPS = 50\n",
        "\n",
        "LOOKUP_STEP = 100\n",
        "\n",
        "SCALE = True\n",
        "scale_str = f\"sc-{int(SCALE)}\"\n",
        "\n",
        "SHUFFLE = True\n",
        "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
        "\n",
        "SPLIT_BY_DATE = False\n",
        "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
        "\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
        "\n",
        "date_now = time.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "N_LAYERS = 2\n",
        "\n",
        "CELL = LSTM\n",
        "\n",
        "UNITS = 256\n",
        "\n",
        "DROPOUT = 0.4\n",
        "\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "LOSS = \"huber_loss\"\n",
        "OPTIMIZER = \"adam\"\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "# Facebook market\n",
        "ticker = \"FB\"\n",
        "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
        "\n",
        "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
        "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
        "if BIDIRECTIONAL:\n",
        "    model_name += \"-b\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMEpN8DXHw3v"
      },
      "source": [
        "\n",
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "if not os.path.isdir(\"logs\"):\n",
        "    os.mkdir(\"logs\")\n",
        "if not os.path.isdir(\"data\"):\n",
        "    os.mkdir(\"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTHfZ04UHyPk",
        "outputId": "ea1a30ef-affa-4a05-e4f8-ef09af092ac5"
      },
      "source": [
        "\n",
        "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
        "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
        "                feature_columns=FEATURE_COLUMNS)\n",
        "\n",
        "data[\"df\"].to_csv(ticker_data_filename)\n",
        "\n",
        "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "\n",
        "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                    callbacks=[checkpointer, tensorboard],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "28/28 [==============================] - 19s 562ms/step - loss: 0.0125 - mean_absolute_error: 0.1028 - val_loss: 0.0027 - val_mean_absolute_error: 0.0552\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00271, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 2/50\n",
            "28/28 [==============================] - 15s 527ms/step - loss: 0.0032 - mean_absolute_error: 0.0542 - val_loss: 0.0022 - val_mean_absolute_error: 0.0409\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.00271 to 0.00221, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 3/50\n",
            "28/28 [==============================] - 14s 504ms/step - loss: 0.0028 - mean_absolute_error: 0.0486 - val_loss: 0.0021 - val_mean_absolute_error: 0.0424\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00221 to 0.00215, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 4/50\n",
            "28/28 [==============================] - 14s 512ms/step - loss: 0.0029 - mean_absolute_error: 0.0510 - val_loss: 0.0021 - val_mean_absolute_error: 0.0406\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00215 to 0.00212, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 5/50\n",
            "28/28 [==============================] - 14s 507ms/step - loss: 0.0029 - mean_absolute_error: 0.0506 - val_loss: 0.0023 - val_mean_absolute_error: 0.0417\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00212\n",
            "Epoch 6/50\n",
            "28/28 [==============================] - 15s 524ms/step - loss: 0.0028 - mean_absolute_error: 0.0496 - val_loss: 0.0021 - val_mean_absolute_error: 0.0405\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.00212\n",
            "Epoch 7/50\n",
            "28/28 [==============================] - 14s 515ms/step - loss: 0.0028 - mean_absolute_error: 0.0495 - val_loss: 0.0023 - val_mean_absolute_error: 0.0456\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00212\n",
            "Epoch 8/50\n",
            "28/28 [==============================] - 14s 517ms/step - loss: 0.0028 - mean_absolute_error: 0.0500 - val_loss: 0.0021 - val_mean_absolute_error: 0.0429\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00212\n",
            "Epoch 9/50\n",
            "28/28 [==============================] - 14s 512ms/step - loss: 0.0028 - mean_absolute_error: 0.0502 - val_loss: 0.0021 - val_mean_absolute_error: 0.0423\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00212\n",
            "Epoch 10/50\n",
            "28/28 [==============================] - 15s 522ms/step - loss: 0.0028 - mean_absolute_error: 0.0500 - val_loss: 0.0021 - val_mean_absolute_error: 0.0415\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00212 to 0.00209, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 11/50\n",
            "28/28 [==============================] - 14s 501ms/step - loss: 0.0026 - mean_absolute_error: 0.0468 - val_loss: 0.0021 - val_mean_absolute_error: 0.0405\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00209 to 0.00207, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 12/50\n",
            "28/28 [==============================] - 14s 497ms/step - loss: 0.0030 - mean_absolute_error: 0.0515 - val_loss: 0.0021 - val_mean_absolute_error: 0.0405\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00207\n",
            "Epoch 13/50\n",
            "28/28 [==============================] - 14s 515ms/step - loss: 0.0028 - mean_absolute_error: 0.0498 - val_loss: 0.0023 - val_mean_absolute_error: 0.0422\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00207\n",
            "Epoch 14/50\n",
            "28/28 [==============================] - 15s 528ms/step - loss: 0.0028 - mean_absolute_error: 0.0502 - val_loss: 0.0021 - val_mean_absolute_error: 0.0404\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00207\n",
            "Epoch 15/50\n",
            "28/28 [==============================] - 14s 507ms/step - loss: 0.0027 - mean_absolute_error: 0.0485 - val_loss: 0.0022 - val_mean_absolute_error: 0.0443\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00207\n",
            "Epoch 16/50\n",
            "28/28 [==============================] - 14s 508ms/step - loss: 0.0030 - mean_absolute_error: 0.0518 - val_loss: 0.0022 - val_mean_absolute_error: 0.0409\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00207\n",
            "Epoch 17/50\n",
            "28/28 [==============================] - 14s 503ms/step - loss: 0.0027 - mean_absolute_error: 0.0480 - val_loss: 0.0022 - val_mean_absolute_error: 0.0433\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00207\n",
            "Epoch 18/50\n",
            "28/28 [==============================] - 14s 515ms/step - loss: 0.0027 - mean_absolute_error: 0.0494 - val_loss: 0.0021 - val_mean_absolute_error: 0.0403\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00207\n",
            "Epoch 19/50\n",
            "28/28 [==============================] - 15s 523ms/step - loss: 0.0027 - mean_absolute_error: 0.0480 - val_loss: 0.0021 - val_mean_absolute_error: 0.0404\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00207\n",
            "Epoch 20/50\n",
            "28/28 [==============================] - 14s 505ms/step - loss: 0.0026 - mean_absolute_error: 0.0484 - val_loss: 0.0021 - val_mean_absolute_error: 0.0407\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00207 to 0.00206, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 21/50\n",
            "28/28 [==============================] - 15s 524ms/step - loss: 0.0026 - mean_absolute_error: 0.0469 - val_loss: 0.0021 - val_mean_absolute_error: 0.0412\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00206\n",
            "Epoch 22/50\n",
            "28/28 [==============================] - 15s 529ms/step - loss: 0.0027 - mean_absolute_error: 0.0490 - val_loss: 0.0021 - val_mean_absolute_error: 0.0406\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00206\n",
            "Epoch 23/50\n",
            "28/28 [==============================] - 15s 535ms/step - loss: 0.0029 - mean_absolute_error: 0.0512 - val_loss: 0.0026 - val_mean_absolute_error: 0.0504\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00206\n",
            "Epoch 24/50\n",
            "28/28 [==============================] - 14s 519ms/step - loss: 0.0031 - mean_absolute_error: 0.0523 - val_loss: 0.0025 - val_mean_absolute_error: 0.0438\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00206\n",
            "Epoch 25/50\n",
            "28/28 [==============================] - 14s 513ms/step - loss: 0.0028 - mean_absolute_error: 0.0497 - val_loss: 0.0023 - val_mean_absolute_error: 0.0412\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00206\n",
            "Epoch 26/50\n",
            "28/28 [==============================] - 14s 512ms/step - loss: 0.0031 - mean_absolute_error: 0.0533 - val_loss: 0.0023 - val_mean_absolute_error: 0.0414\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00206\n",
            "Epoch 27/50\n",
            "28/28 [==============================] - 14s 509ms/step - loss: 0.0029 - mean_absolute_error: 0.0512 - val_loss: 0.0022 - val_mean_absolute_error: 0.0439\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00206\n",
            "Epoch 28/50\n",
            "28/28 [==============================] - 14s 495ms/step - loss: 0.0028 - mean_absolute_error: 0.0492 - val_loss: 0.0021 - val_mean_absolute_error: 0.0403\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00206 to 0.00206, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 29/50\n",
            "28/28 [==============================] - 14s 518ms/step - loss: 0.0027 - mean_absolute_error: 0.0486 - val_loss: 0.0022 - val_mean_absolute_error: 0.0451\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00206\n",
            "Epoch 30/50\n",
            "28/28 [==============================] - 15s 521ms/step - loss: 0.0027 - mean_absolute_error: 0.0473 - val_loss: 0.0022 - val_mean_absolute_error: 0.0409\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00206\n",
            "Epoch 31/50\n",
            "28/28 [==============================] - 14s 511ms/step - loss: 0.0025 - mean_absolute_error: 0.0475 - val_loss: 0.0024 - val_mean_absolute_error: 0.0434\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00206\n",
            "Epoch 32/50\n",
            "28/28 [==============================] - 14s 489ms/step - loss: 0.0028 - mean_absolute_error: 0.0487 - val_loss: 0.0055 - val_mean_absolute_error: 0.0831\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00206\n",
            "Epoch 33/50\n",
            "28/28 [==============================] - 14s 496ms/step - loss: 0.0034 - mean_absolute_error: 0.0554 - val_loss: 0.0023 - val_mean_absolute_error: 0.0418\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00206\n",
            "Epoch 34/50\n",
            "28/28 [==============================] - 15s 521ms/step - loss: 0.0026 - mean_absolute_error: 0.0470 - val_loss: 0.0023 - val_mean_absolute_error: 0.0453\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00206\n",
            "Epoch 35/50\n",
            "28/28 [==============================] - 15s 523ms/step - loss: 0.0031 - mean_absolute_error: 0.0518 - val_loss: 0.0021 - val_mean_absolute_error: 0.0406\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00206\n",
            "Epoch 36/50\n",
            "28/28 [==============================] - 14s 508ms/step - loss: 0.0025 - mean_absolute_error: 0.0470 - val_loss: 0.0025 - val_mean_absolute_error: 0.0500\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00206\n",
            "Epoch 37/50\n",
            "28/28 [==============================] - 14s 509ms/step - loss: 0.0028 - mean_absolute_error: 0.0504 - val_loss: 0.0024 - val_mean_absolute_error: 0.0427\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00206\n",
            "Epoch 38/50\n",
            "28/28 [==============================] - 14s 504ms/step - loss: 0.0027 - mean_absolute_error: 0.0485 - val_loss: 0.0020 - val_mean_absolute_error: 0.0409\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.00206 to 0.00205, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 39/50\n",
            "28/28 [==============================] - 14s 513ms/step - loss: 0.0025 - mean_absolute_error: 0.0465 - val_loss: 0.0020 - val_mean_absolute_error: 0.0403\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00205 to 0.00204, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 40/50\n",
            "28/28 [==============================] - 14s 508ms/step - loss: 0.0026 - mean_absolute_error: 0.0466 - val_loss: 0.0021 - val_mean_absolute_error: 0.0400\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00204\n",
            "Epoch 41/50\n",
            "28/28 [==============================] - 14s 507ms/step - loss: 0.0025 - mean_absolute_error: 0.0468 - val_loss: 0.0021 - val_mean_absolute_error: 0.0403\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00204\n",
            "Epoch 42/50\n",
            "28/28 [==============================] - 14s 498ms/step - loss: 0.0025 - mean_absolute_error: 0.0467 - val_loss: 0.0024 - val_mean_absolute_error: 0.0481\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00204\n",
            "Epoch 43/50\n",
            "28/28 [==============================] - 14s 512ms/step - loss: 0.0028 - mean_absolute_error: 0.0495 - val_loss: 0.0023 - val_mean_absolute_error: 0.0418\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00204\n",
            "Epoch 44/50\n",
            "28/28 [==============================] - 14s 509ms/step - loss: 0.0028 - mean_absolute_error: 0.0496 - val_loss: 0.0020 - val_mean_absolute_error: 0.0397\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00204 to 0.00203, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n",
            "Epoch 45/50\n",
            "28/28 [==============================] - 14s 508ms/step - loss: 0.0026 - mean_absolute_error: 0.0471 - val_loss: 0.0022 - val_mean_absolute_error: 0.0446\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00203\n",
            "Epoch 46/50\n",
            "28/28 [==============================] - 14s 497ms/step - loss: 0.0025 - mean_absolute_error: 0.0481 - val_loss: 0.0023 - val_mean_absolute_error: 0.0427\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00203\n",
            "Epoch 47/50\n",
            "28/28 [==============================] - 14s 501ms/step - loss: 0.0025 - mean_absolute_error: 0.0464 - val_loss: 0.0020 - val_mean_absolute_error: 0.0413\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00203\n",
            "Epoch 48/50\n",
            "28/28 [==============================] - 14s 513ms/step - loss: 0.0024 - mean_absolute_error: 0.0456 - val_loss: 0.0021 - val_mean_absolute_error: 0.0411\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00203\n",
            "Epoch 49/50\n",
            "28/28 [==============================] - 14s 505ms/step - loss: 0.0025 - mean_absolute_error: 0.0470 - val_loss: 0.0021 - val_mean_absolute_error: 0.0430\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00203\n",
            "Epoch 50/50\n",
            "28/28 [==============================] - 14s 507ms/step - loss: 0.0025 - mean_absolute_error: 0.0464 - val_loss: 0.0020 - val_mean_absolute_error: 0.0400\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00203 to 0.00202, saving model to results/2021-07-29_FB-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-100-layers-2-units-256.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9zCHUR3H1dt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graph(test_df):\n",
        "    \n",
        "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
        "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
        "    plt.xlabel(\"Days\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk_PYOIbH2D0"
      },
      "source": [
        "def get_final_df(model, data):\n",
        "    \n",
        "\n",
        "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
        "    \n",
        "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_test = data[\"y_test\"]\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    if SCALE:\n",
        "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    test_df = data[\"test_df\"]\n",
        "    \n",
        "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
        "  \n",
        "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
        "    \n",
        "    test_df.sort_index(inplace=True)\n",
        "    final_df = test_df\n",
        "    \n",
        "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
        "                                    final_df[\"adjclose\"], \n",
        "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
        "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
        "                                    \n",
        "                                    )\n",
        "    \n",
        "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
        "                                    final_df[\"adjclose\"], \n",
        "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
        "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
        "                              \n",
        "                                    )\n",
        "    return final_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BZUuCKWH4Up"
      },
      "source": [
        "def predict(model, data):\n",
        "   \n",
        "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
        "   \n",
        "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        " \n",
        "    prediction = model.predict(last_sequence)\n",
        "\n",
        "    if SCALE:\n",
        "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
        "    else:\n",
        "        predicted_price = prediction[0][0]\n",
        "    return predicted_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO9p7dCQH6zH"
      },
      "source": [
        "\n",
        "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
        "model.load_weights(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLSmcFAnH-C2"
      },
      "source": [
        "\n",
        "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "\n",
        "if SCALE:\n",
        "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
        "else:\n",
        "    mean_absolute_error = mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGDA-l_FIDSE"
      },
      "source": [
        "\n",
        "final_df = get_final_df(model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOApRHskIDoW"
      },
      "source": [
        "future_price = predict(model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejvAoGZTIFnY"
      },
      "source": [
        "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
        "\n",
        "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
        "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
        "\n",
        "total_profit = total_buy_profit + total_sell_profit\n",
        "\n",
        "profit_per_trade = total_profit / len(final_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DHacPa-IHoi"
      },
      "source": [
        "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
        "\n",
        "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
        "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
        "\n",
        "total_profit = total_buy_profit + total_sell_profit\n",
        "\n",
        "profit_per_trade = total_profit / len(final_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FJQX8qp4q5U",
        "outputId": "a9595aff-3688-4f96-efdf-c1792b2d7a26"
      },
      "source": [
        "# printing metrics\n",
        "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
        "print(f\"{LOSS} loss:\", loss)\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
        "print(\"Accuracy score:\", accuracy_score)\n",
        "print(\"Total buy profit:\", total_buy_profit)\n",
        "print(\"Total sell profit:\", total_sell_profit)\n",
        "print(\"Total profit:\", total_profit)\n",
        "print(\"Profit per trade:\", profit_per_trade)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Future price after 100 days is 420.12$\n",
            "huber_loss loss: 0.002015833742916584\n",
            "Mean Absolute Error: 31.95929601287021\n",
            "Accuracy score: 0.8175519630484989\n",
            "Total buy profit: 4424.207670211792\n",
            "Total sell profit: -875.9628467559814\n",
            "Total profit: 3548.2448234558105\n",
            "Profit per trade: 8.194560793200486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "pgyGjgUXIJfw",
        "outputId": "04fd8241-74fe-4a93-9c56-990c20796e5c"
      },
      "source": [
        "plot_graph(final_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjyU59W3IMmb"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('mymodel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIMG0FMsIN7D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}